{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkCz3OMIiaaS"
      },
      "source": [
        "# 환경 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQBeOG4YiRw5"
      },
      "source": [
        "## 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSgszx4nszTa"
      },
      "source": [
        "import os\n",
        "from typing import Tuple, List, Sequence, Callable\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "import torchvision.models as models\n",
        "\n",
        "!pip install facenet-pytorch\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "\n",
        "!pip install torch_optimizer\n",
        "import torch_optimizer as optim\n",
        "\n",
        "!pip install -U git+https://github.com/albu/albumentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgEOL7Sbidee"
      },
      "source": [
        "## 구글 드라이브 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlHop6LvtYK0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ6FQryXt49j"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/statml_competition/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpqgWBy5u7RO"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zv3T5Utu-kc"
      },
      "source": [
        "device = \"cuda:0\"\n",
        "dtype = torch.float\n",
        "ltype = torch.long # entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Fd1xGli3F9"
      },
      "source": [
        "## Hyperparameter 셋팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "456_opQfi5Ns"
      },
      "source": [
        "random_seed = 42\n",
        "\n",
        "batch_size = 64\n",
        "validation_ratio = 0.05\n",
        "\n",
        "num_epochs = 60\n",
        "learning_rate = 0.0015\n",
        "betas = (0.9, 0.999)\n",
        "weight_decay = 1e-4\n",
        "T_max = 50\n",
        "\n",
        "num_workers = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs2ostuPjBB9"
      },
      "source": [
        "## Randomness 제어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqzmrgb6jFd6"
      },
      "source": [
        "# 1. Pytorch\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "\n",
        "# 2. CuDNN\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True # 원래 False 여야 랜덤 제어\n",
        "\n",
        "# 3. Numpy\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# 4. random (for torchvision transforms)\n",
        "random.seed(random_seed)\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf3THh7UitGa"
      },
      "source": [
        "# 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ll6NYeBvDES"
      },
      "source": [
        "## CSV파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "HXhcU2wEvFmE",
        "outputId": "73d9df95-cc7b-48e6-9bc2-240caa1fb562"
      },
      "source": [
        "# fake 1, real 0 로 사용\n",
        "train_df = pd.read_csv('./face_image/face_images.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>real</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./face_image/fake/JFH50GFJUL.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./face_image/fake/0VPS5TI60G.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./face_image/real/61911.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./face_image/fake/APADHGXN31.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./face_image/fake/SJO2UL69C2.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               path  real  fake\n",
              "0  ./face_image/fake/JFH50GFJUL.jpg     0     1\n",
              "1  ./face_image/fake/0VPS5TI60G.jpg     0     1\n",
              "2       ./face_image/real/61911.jpg     1     0\n",
              "3  ./face_image/fake/APADHGXN31.jpg     0     1\n",
              "4  ./face_image/fake/SJO2UL69C2.jpg     0     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kvaQdPRvSjs",
        "outputId": "77e1d7d3-352a-4ff9-f527-302e2c658256"
      },
      "source": [
        "print(train_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynWYJ0zZEodO"
      },
      "source": [
        "## 커스텀 데이터 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO82SRIoFPdE"
      },
      "source": [
        "class FaceDataset(Dataset):\n",
        "  def __init__(self, image_label, transforms) :\n",
        "    self.df = image_label\n",
        "    self.transforms = transforms\n",
        "        \n",
        "  def __len__(self) -> int:\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index: int) -> Tuple[Tensor]:\n",
        "    assert index <= len(self), 'index range error' \n",
        "      \n",
        "    image_dir = self.df.iloc[index, ]['path']\n",
        "    image_id = self.df.iloc[index, ]['fake'].astype(np.int64)\n",
        "    \n",
        "    image =  cv2.imread(image_dir, cv2.COLOR_BGR2RGB)\n",
        "    target = torch.as_tensor(image_id, dtype=torch.long)\n",
        "\n",
        "    if self.transforms is not None :\n",
        "      image = self.transforms(image=image)['image']\n",
        "    \n",
        "    #image = image/255.0\n",
        "\n",
        "    return image, target\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, image, transforms) :\n",
        "    self.image = image\n",
        "    self.transforms = transforms\n",
        "        \n",
        "  def __len__(self) -> int:\n",
        "    return len(self.image)\n",
        "\n",
        "  def __getitem__(self, index: int) -> Tuple[Tensor]:\n",
        "    assert index <= len(self), 'index range error' \n",
        "    \n",
        "    image_name = self.image[index]\n",
        "    image_dir = './face_image/test_v1.1/' + image_name\n",
        "\n",
        "    image =  cv2.imread(image_dir, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    if self.transforms is not None :\n",
        "      image = self.transforms(image=image)['image']\n",
        "\n",
        "    #image = image/255.0\n",
        "\n",
        "    return image_name, image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S3I6yugFWk8"
      },
      "source": [
        "## 이미지 어그멘테이션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlnmo824Gg-R"
      },
      "source": [
        "transforms_tr = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.ImageCompression(quality_lower=60, quality_upper=100, p=0.5),\n",
        "    A.GaussNoise(p=0.1),\n",
        "    A.GaussianBlur(blur_limit=3, p=0.05),\n",
        "    A.HorizontalFlip(),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(), \n",
        "        A.FancyPCA(), \n",
        "        A.HueSaturationValue(),\n",
        "    ], p=0.7),\n",
        "    A.ToGray(p=0.2),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
        "    A.CenterCrop(156, 156),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "transforms_val = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.CenterCrop(156, 156),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(), \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u8MWHJ1FgM4"
      },
      "source": [
        "## 데이터셋 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS6VccHHFiQg",
        "outputId": "e2489c83-d10e-40b6-f61f-09ec4cb54eda"
      },
      "source": [
        "#train : valid = 9 : 1\n",
        "train, valid = train_test_split(train_df, test_size=validation_ratio)\n",
        "\n",
        "print(f'Train Set dim : (%d, %d)' % (train.shape))\n",
        "print(f'Valid Set dim : (%d, %d)' % (valid.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set dim : (19000, 3)\n",
            "Valid Set dim : (1000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s167Wrs8FlG-"
      },
      "source": [
        "tr_dataset = FaceDataset(image_label=train, transforms=transforms_tr)\n",
        "val_dataset = FaceDataset(image_label=valid, transforms=transforms_val)\n",
        "\n",
        "train_loader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRoW9W1DFn5N",
        "outputId": "94154b6d-9268-4b13-db6c-f7d31227c289"
      },
      "source": [
        "print(\"train set size :\",len(tr_dataset))\n",
        "print(\"valid set size :\",len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size : 19000\n",
            "valid set size : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGEhtUpJ8EMv"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGc8IrOI8FSJ"
      },
      "source": [
        "EARLY_STOPPING_EPOCH = 7\n",
        "n_splits = 4\n",
        "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
        "\n",
        "best_models = {}\n",
        "fold_results = {}\n",
        "\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(train_df)):\n",
        "  print(f' ---------------------- Fold %d --------------------------------------------' % (fold+1) )\n",
        "  \n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  train = train_df.iloc[train_ids]\n",
        "  valid = train_df.iloc[test_ids]\n",
        "\n",
        "  tr_dataset = FaceDataset(image_label=train, transforms=transforms_tr)\n",
        "  val_dataset = FaceDataset(image_label=valid, transforms=transforms_val)\n",
        "\n",
        "  train_loader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "  valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "  # Create model\n",
        "  model = InceptionResnetV1(pretrained=None, classify=True, num_classes=2, dropout_prob=0.6)\n",
        "  model.to(device)\n",
        "\n",
        "  optimizer = optim.RAdam(model.parameters(), lr=learning_rate, betas=betas, weight_decay=weight_decay)\n",
        "  lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_max)\n",
        "\n",
        "  # early stopping\n",
        "  valid_early_stop = 0\n",
        "  valid_best_loss = float('inf')\n",
        "  since = time.time()\n",
        "\n",
        "  for e in range(num_epochs) :\n",
        "    print(f' ====================== epoch %d ======================' % (e+1) )\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "\n",
        "    # train\n",
        "    model.train()\n",
        "    for i, (images, targets) in enumerate(train_loader) : \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      images = images.to(device, dtype)\n",
        "      targets = targets.to(device, ltype)\n",
        "    \n",
        "      scores = model(images)\n",
        "      _, preds = scores.max(dim=1)\n",
        "\n",
        "      loss = F.cross_entropy(scores, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      correct = sum(targets == preds).cpu()\n",
        "      acc=(correct/batch_size * 100)\n",
        "\n",
        "      train_loss_list.append(loss)\n",
        "      train_acc_list.append(acc)\n",
        "\n",
        "      if i % 100 == 0 :\n",
        "        print(f'Iteration %3.d | Train Loss  %.4f | Classifier Accuracy %2.2f' % (i, loss, acc))\n",
        "\n",
        "    train_mean_loss = np.mean(train_loss_list, dtype=\"float64\")\n",
        "    train_mean_acc = np.mean(train_acc_list, dtype=\"float64\")\n",
        "\n",
        "    epoch_time = time.time() - since\n",
        "    since = time.time()\n",
        "\n",
        "    print('')\n",
        "    print(f'[Summary] Elapsed time : %.0f m %.0f s' % (epoch_time // 60, epoch_time % 60))\n",
        "    print(f'Train Loss Mean %.4f | Accuracy %2.2f ' % (train_mean_loss, train_mean_acc) )\n",
        "\n",
        "    # validation \n",
        "    model.eval()\n",
        "    valid_loss_list = []\n",
        "    valid_acc_list = []\n",
        "    for i, (images, targets) in enumerate(valid_loader) : \n",
        "      optimizer.zero_grad()\n",
        "      images = images.to(device=device, dtype=dtype)\n",
        "      targets = targets.to(device=device, dtype=ltype)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        scores = model(images)\n",
        "        loss = F.cross_entropy(scores, targets)\n",
        "        _, preds = scores.max(dim=1)\n",
        "      \n",
        "      correct = sum(targets == preds).cpu()\n",
        "      acc=(correct/batch_size * 100)\n",
        "\n",
        "      valid_loss_list.append(loss)\n",
        "      valid_acc_list.append(acc)\n",
        "  \n",
        "    val_mean_loss = np.mean(valid_loss_list, dtype=\"float64\")\n",
        "    val_mean_acc = np.mean(valid_acc_list, dtype=\"float64\")\n",
        "\n",
        "    print(f'Valid Loss Mean %.4f | Accuracy %2.2f ' % (val_mean_loss, val_mean_acc) )\n",
        "    print('')\n",
        "\n",
        "    if val_mean_loss < valid_best_loss:\n",
        "      valid_best_loss = val_mean_loss\n",
        "      valid_early_stop = 0  \n",
        "      # new best model save (valid 기준)\n",
        "      best_model = model\n",
        "      best_models[fold] = best_model\n",
        "      # 저장\n",
        "      path = './'\n",
        "      torch.save(best_model.state_dict(), f'{path}fold{fold}model{val_mean_acc:2.2f}_epoch_{e}.pth')\n",
        "      # update fold result\n",
        "      fold_results[fold] = {\"train_mean_acc\" : train_mean_acc, \n",
        "                            \"train_mean_loss\" : train_mean_loss, \n",
        "                            \"val_mean_acc\" : val_mean_acc, \n",
        "                            \"val_mean_loss\" : val_mean_loss,\n",
        "                            \"epoch\" : e}\n",
        "\n",
        "    else:\n",
        "      # early stopping    \n",
        "      valid_early_stop += 1\n",
        "      if valid_early_stop >= EARLY_STOPPING_EPOCH:  # patience\n",
        "        print(\"EARLY STOPPING!!\")\n",
        "        break\n",
        "\n",
        "    lr_sched.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2SMX0x35-N7"
      },
      "source": [
        "# **추론**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQoBgS3Ju2pY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "572bd0e8-ed9b-49b7-ef9e-1a94ff2e7b97"
      },
      "source": [
        "submission = pd.read_csv(\"./face_image/submission_v1.1.csv\")\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test14200.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test12178.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test12713.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test13712.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test11739.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           image  label\n",
              "0  test14200.jpg    NaN\n",
              "1  test12178.jpg    NaN\n",
              "2  test12713.jpg    NaN\n",
              "3  test13712.jpg    NaN\n",
              "4  test11739.jpg    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbM6opgyutmM"
      },
      "source": [
        "test_dataset = TestDataset(submission['image'], transforms_val)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF2-cbHru5cj"
      },
      "source": [
        "scores_result = []\n",
        "\n",
        "for fold in range(n_splits):\n",
        "  model = best_models[fold]\n",
        "  #path = './model/'\n",
        "  #val_mean_acc = fold_results[fold]['val_mean_acc']\n",
        "  #e = fold_results[fold]['epoch']\n",
        "  #mypath = f'{path}fold{fold}model{val_mean_acc:2.2f}_epoch_{e}.pth'\n",
        "  #checkpoint = torch.load(mypath)\n",
        "  #model.load_state_dict(checkpoint)\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  predictions = []\n",
        "  files = []\n",
        "  score_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for img_names, images in test_loader:\n",
        "      images = images.to(device=device, dtype=dtype)\n",
        "      scores = model(images)\n",
        "      _, preds = scores.max(dim=1)\n",
        "      \n",
        "      files.extend(img_names)\n",
        "      predictions.extend(preds.squeeze(0).detach().cpu().numpy())\n",
        "      score_list.extend(scores.squeeze(0).detach().cpu().numpy())\n",
        "  scores_result.append(score_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkkRJuXQ9sb0"
      },
      "source": [
        "myresult = torch.tensor(scores_result)\n",
        "print(myresult.shape)\n",
        "myresult = F.softmax(myresult, dim=2)\n",
        "print(myresult.shape)\n",
        "myresult = torch.sum(myresult, dim=0)\n",
        "print(myresult.shape)\n",
        "\n",
        "_, preds = myresult.max(dim=1)\n",
        "\n",
        "ensemble_sub = pd.DataFrame(columns=submission.columns)\n",
        "ensemble_sub['image'] = files\n",
        "ensemble_sub['label'] = preds\n",
        "\n",
        "csvfilename = \"./submission_group2.csv\"\n",
        "ensemble_sub.to_csv(csvfilename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oesdfY_bz2QW",
        "outputId": "37be9b48-5f5b-4283-8c6f-b88e024c039b"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(csvfilename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_880c7a7b-5e5a-4443-9db4-8461575d3576\", \"submission_0605_resize256.csv\", 80012)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
